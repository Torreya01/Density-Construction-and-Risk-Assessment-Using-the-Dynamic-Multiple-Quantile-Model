} else {
year <- year + 1900
}
date_string_full_year = paste(date_parts[1], date_parts[2], year, sep = "/")
parsed_date = as.Date(date_string_full_year, format = "%m/%d/%Y")
formatted_date = format(parsed_date, "%Y/%m/%d")
return(formatted_date)
}
View(FTSE)
# Apply the conversion function to the date_string column
FTSE = FTSE %>%
mutate(Date = sapply(Date, convert_date))
View(FTSE)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Close = as.numeric(FTSE$Close)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Step 3: Convert the cleaned Price column to numeric
FTSE$Close = as.numeric(FTSE$Close)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Turn FTSE$Date into Date object
FTSE$Date = as.Date(FTSE$Date)
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Close = as.numeric(FTSE$Close)
View(FTSE)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
View(FTSE)
# Turn FTSE$Date into Date object
FTSE$Date = as.Date(FTSE$Date)
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
View(FTSE)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Function to convert date format
convert_date = function(date_string) {
date_parts = strsplit(date_string, "/")[[1]]
year = as.numeric(date_parts[3])
if (year < 50) {
year <- year + 2000
} else {
year <- year + 1900
}
date_string_full_year = paste(date_parts[1], date_parts[2], year, sep = "/")
parsed_date = as.Date(date_string_full_year, format = "%m/%d/%Y")
formatted_date = format(parsed_date, "%Y/%m/%d")
return(formatted_date)
}
# Apply the conversion function to the date_string column
FTSE = FTSE %>%
mutate(Date = sapply(Date, convert_date))
# Turn FTSE$Date into Date object
FTSE$Date = as.Date(FTSE$Date)
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
View(FTSE)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Turn FTSE$Date into Date object
FTSE$Date = as.Date(FTSE$Date)
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Import data of apple share prices
apple = read.csv("Data/apple_share_prices.csv")
View(apple)
# Turn FTSE$Date into Date object
FTSE$Date = as.Date(FTSE$Date)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Convert to Date object with the original format
FTSE$Date <- as.Date(FTSE$Date, format = "%d/%m/%Y")
# Convert to Date object with the original format
FTSE$Date = as.Date(FTSE$Date, format = "%d/%m/%Y")
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Price = as.numeric(FTSE$Price)
View(FTSE)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Convert to Date object with the original format
FTSE$Date = as.Date(FTSE$Date, format = "%d/%m/%Y")
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
class(FTSE$Price)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Price = as.numeric(FTSE$Price)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Convert to Date object with the original format
FTSE$Date = as.Date(FTSE$Date, format = "%d/%m/%Y")
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Price = as.numeric(FTSE$Price)
View(FTSE)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Convert to Date object with the original format
FTSE$Date = as.Date(FTSE$Date, format = "%d/%m/%Y")
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
# Step 3: Convert the cleaned Price column to numeric
FTSE$High = as.numeric(FTSE$High)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Open = as.numeric(FTSE$Open)
# Import data of FTSE share prices
FTSE = read.csv("Data/FTSE_100.csv")
# Convert to Date object with the original format
FTSE$Date = as.Date(FTSE$Date, format = "%d/%m/%Y")
# Sort the date of the data
FTSE$Date = sort(FTSE$Date)
# Step 3: Convert the cleaned Price column to numeric
FTSE$Open = as.numeric(FTSE$Open)
# Import data of apple share prices
apple = read.csv("Data/apple_share_prices.csv")
# Turn apple$Date into Date object
apple$Date = as.Date(apple$Date)
# Convert the cleaned Price column to numeric
apple$Close = as.numeric(apple$Close)
# Set up the date limits
date_limits = range(apple$Date, na.rm = TRUE)
# Make a new data column that contains the differences between each log entry
apple$log = log(apple$Close)
apple_diff = apple[-1, ]
apple_diff = diff(apple$log)
# Read the RDS file fit
Fit_apple = readRDS(file = "Data/Fitted_RDS/Fit_apple.rds")
# Extract the quantiles from the fit and eliminate the first column
quantiles = Fit_apple$lFilter$mQ
quantiles = quantiles[,-1]
apple = apple[-1,]
# Select four random dates to see what the density plots look like
selected_columns = c(300, 1300, 2000, 2516)
mQ_days = quantiles[, selected_columns]
# Select a whole month 6/5 to 7/5 and see what the density plots look like
selected_month = c(2515, 2516)
mQ_month = quantiles[, selected_month]
# Plot the random selected density plots into a four plot column
par(mfrow = c(4,1))
# 30-steps ahead
Forecast_apple_30 = ForecastDMQ(Fit_apple, 30)
# Import libraries
library(DMQ)
library(np)
library(ks)
library(ggplot2)
library(moments)
library(dplyr)
library(lubridate)
# 30-steps ahead
Forecast_apple_30 = ForecastDMQ(Fit_apple, 30)
head(Forecast_apple_30)
Forecast_30 = sort(as.vector(Forecast_apple_30))
Forecast_30
# Plot the forecasts into a density plot
bw_ls = npudensbw(Forecast_30, ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(Forecast_30, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$Forecast_30, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
Forecast_30
head(Forecast_30)
tail(Forecast_30)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(Forecast_30, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$Forecast_30, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
kde_ls_frame$Quantile
kde_ls_frame$Density
mean(Forecast_30)
mean(kde_2019_1)
# Extract the year from the Date column
apple$Year = year(apple$Date)
apple$Month = month(apple$Date)
# Read the kde results
kde_results = readRDS(file = "Data/Fitted_RDS/kde_result.rds")
# Combine all KDE results into a single data frame
kde_all = do.call(rbind, kde_results)
# Define the color palette
colors = c("1" = "black", "2" = "blue", "3" = "red", "4" = "green",
"5" = "purple", "6" = "yellow", "7" = "orange", "8" = "pink",
"9" = "cyan", "10" = "brown", "11" = "magenta", "12" = "turquoise")
# List of months to plot
months = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12")
years = c("2014", "2015", "2016", "2017", "2018",
"2019", "2020", "2021", "2022", "2023", "2024")
# Loop through each month and create the plots
for (year in years) {
# Subset the data for the current year
kde_year = kde_all %>% filter(Year == year)
# Create the plot
p = ggplot(kde_year, aes(x = Quantile, y = Density, color = Month, group = Month)) +
geom_line(linewidth = 1) +
labs(title = paste("Density Plot for Year", year),
x = "Quantile", y = "Density") +
theme_minimal() +
theme(legend.title = element_blank()) +
scale_color_manual(values = colors, breaks = months)
# Print the plot
print(p)
}
kde_2019_1 = kde_all %>% filter(Year == 2019) %>% filter(Month == 1)
kde_2019_2 = kde_all %>% filter(Year == 2019) %>% filter(Month == 2)
mean(kde_2019_1$Quantile)
mean(kde_2019_2$Quantile)
mean(kde_ls_frame$Density)
mean(kde_2019_2$Density)
head(Forecast_30)
nrow(kde_2019_1)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
Forecast_5 = sort(as.vector(Forecast_apple_5))
# Five-step ahead
Forecast_apple_5 = ForecastDMQ(Fit_apple, 5)
Forecast_5 = sort(as.vector(Forecast_apple_5))
# Plot the forecasts into a density plot
bw_ls = npudensbw(Forecast_30, ckertype = "gaussian", bwmethod = "cv.ls")
# Plot the forecasts into a density plot
bw_ls = npudensbw(Forecast_5, ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(Forecast_5, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$Forecast_5, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
# Make the a month forecasts into a whole list
Forecast_30 = sort(as.vector(Forecast_apple_30))
# Plot the forecasts into a density plot
bw_ls = npudensbw(Forecast_30, ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(Forecast_30, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$Forecast_30, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
(VaR)
VaR(Forecast_30, p = 0.95, method = "historical")
# Calculate Expected Shortfall (ES)
ES(Forecas
)
# Calculate Value at Risk (VaR)
VaR(Forecast_30, p = 0.95, method = "historical")
# Calculate Expected Shortfall (ES)
ES(Forecast_30, p = 0.95, method = "historical")
kde_2020_10 = kde_all %>% filter(Year == 2020) %>% filter(Month == 10)
plot(kde_2020_10$Quantile, kde_2020_10$Density, type = "l")
# Calculate the 95th percentile threshold
threshold_11 = quantile(kde_2020_10$Quantile, 0.95)
# Select the top 5% of data values
upper_tail_data_11 = kde_2020_10 %>% filter(kde_2020_10$Quantile > threshold_11)
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls = npudensbw(upper_tail_data_11$Quantile, ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(upper_tail_data_11$Quantile, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$upper_tail_data_1, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
qqnorm(kde_ls_frame$Quantile, main = "QQ Plot")
qqline(kde_ls_frame$Quantile, col = "red")
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
qqnorm(kde_ls_frame$Quantile, main = "QQ Plot")
qqline(kde_ls_frame$Quantile, col = "red")
# Make the a month forecasts into a whole list
Forecast_30 = sort(as.vector(Forecast_apple_30))
# Plot the forecasts into a density plot
bw_ls = npudensbw(Forecast_30, ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(Forecast_30, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$Forecast_30, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
Forecast_5 = sort(as.vector(Forecast_apple_5))
# Plot the forecasts into a density plot
bw_ls = npudensbw(Forecast_5, ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(Forecast_5, bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$Forecast_5, Density = kde_ls$dens)
# Add lines to the original density plot
plot(kde_ls_frame$Quantile, kde_ls_frame$Density, type = "l")
# Calculate Value at Risk (VaR)
VaR(Forecast_5, p = 0.95, method = "historical")
# Calculate Expected Shortfall (ES)
ES(Forecast_5, p = 0.95, method = "historical")
# Plot the random selected density plots into a four plot column
par(mfrow = c(5,1))
# Plot the actual results of the forecast results from the DMQ model
for (i in 1:5) {
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls = npudensbw(mQ_compare[, i], ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(mQ_compare[, i], bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$mQ_compare, Density = kde_ls$dens)
# Plotting using ggplot2
plot(kde_ls_frame, type = "l",
main = paste("Denity plot for apple on", apple_new[compare_select[i], "Date"]))
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls_forecast = npudensbw(Forecast_apple_5[i, ], ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls_forecast = npudens(Forecast_apple_5[i, ], bws = bw_ls_forecast, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame_forecast = data.frame(Quantile = kde_ls_forecast$eval$Forecast_apple_5, Density = kde_ls_forecast$dens)
# Plotting using ggplot2
lines(kde_ls_frame_forecast, type = "l", col = "blue")
}
# Select the last 5 days of the data and plot density
compare_select = c(2517, 2518, 2519, 2520, 2521)
mQ_compare = quantiles_new[, compare_select]
# Plot the random selected density plots into a four plot column
par(mfrow = c(5,1))
# Plot the actual results of the forecast results from the DMQ model
for (i in 1:5) {
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls = npudensbw(mQ_compare[, i], ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(mQ_compare[, i], bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$mQ_compare, Density = kde_ls$dens)
# Plotting using ggplot2
plot(kde_ls_frame, type = "l",
main = paste("Denity plot for apple on", apple_new[compare_select[i], "Date"]))
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls_forecast = npudensbw(Forecast_apple_5[i, ], ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls_forecast = npudens(Forecast_apple_5[i, ], bws = bw_ls_forecast, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame_forecast = data.frame(Quantile = kde_ls_forecast$eval$Forecast_apple_5, Density = kde_ls_forecast$dens)
# Plotting using ggplot2
lines(kde_ls_frame_forecast, type = "l", col = "blue")
}
# Read the RDS file fit
Fit_apple_new = readRDS(file = "Data/Fitted_RDS/Fit_apple_new.rds")
# Extract the quantiles from the fit and eliminate the first column
quantiles_new = Fit_apple_new$lFilter$mQ
quantiles_new = quantiles_new[,-1]
apple_new = apple_new[-1, ]
# Select the last 5 days of the data and plot density
compare_select = c(2517, 2518, 2519, 2520, 2521)
mQ_compare = quantiles_new[, compare_select]
################# Compare the existing result with the forecast ###############
# Load the new data set
apple_new = read.csv("Data/apple_share_prices_new.csv")
# Turn apple$Date into Date object
apple_new$Date = as.Date(apple_new$Date)
# Convert the cleaned Price column to numeric
apple_new$Close = as.numeric(apple_new$Close)
# Set up the date limits
date_limits_new = range(apple_new$Date, na.rm = TRUE)
# Make a new data column that contains the differences between each log entry
apple_new$log = log(apple_new$Close)
apple_diff_new = apple_new[-1, ]
apple_diff_new = diff(apple_new$log)
# Read the RDS file fit
Fit_apple_new = readRDS(file = "Data/Fitted_RDS/Fit_apple_new.rds")
# Extract the quantiles from the fit and eliminate the first column
quantiles_new = Fit_apple_new$lFilter$mQ
quantiles_new = quantiles_new[,-1]
apple_new = apple_new[-1, ]
# Select the last 5 days of the data and plot density
compare_select = c(2517, 2518, 2519, 2520, 2521)
mQ_compare = quantiles_new[, compare_select]
# Plot the random selected density plots into a four plot column
par(mfrow = c(5,1))
# Plot the actual results of the forecast results from the DMQ model
for (i in 1:5) {
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls = npudensbw(mQ_compare[, i], ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls = npudens(mQ_compare[, i], bws = bw_ls, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame = data.frame(Quantile = kde_ls$eval$mQ_compare, Density = kde_ls$dens)
# Plotting using ggplot2
plot(kde_ls_frame, type = "l",
main = paste("Denity plot for apple on", apple_new[compare_select[i], "Date"]))
# Compute optimal bandwidth using cross-validation on Maximum Likelihood
bw_ls_forecast = npudensbw(Forecast_apple_5[i, ], ckertype = "gaussian", bwmethod = "cv.ls")
# Perform kernel density estimation using the optimal bandwidth
kde_ls_forecast = npudens(Forecast_apple_5[i, ], bws = bw_ls_forecast, ckertype = "gaussian")
# Convert KDE result to data frame for plotting
kde_ls_frame_forecast = data.frame(Quantile = kde_ls_forecast$eval$Forecast_apple_5, Density = kde_ls_forecast$dens)
# Plotting using ggplot2
lines(kde_ls_frame_forecast, type = "l", col = "blue")
}
mean(apple_diff)
var(apple_diff)
sd(apple_diff)
# Load necessary library
library(MASS)
library(DMQ)
# Set the Gaussian samples
# Parameters for two normal Gaussians
mean1 = 0.0009
var1 = 0.0003
mean2 = 0.0005
var2 = 0.0005
# Parameters for mixed Gaussian (mixture of two normal distributions)
mean_mix1 = 0.0009
var_mix1 = 0.0003
mean_mix2 = 0.0005
var_mix2 = 0.0005
prob_mix = c(0.6, 0.4)
mean_mix = prob_mix[1] * mean_mix1 + prob_mix[2] * mean_mix2
var_mix = prob_mix[1] * var_mix1 + prob_mix[2] * var_mix2
# Parameters for student-t distribution with degree of freedom 4
t = 4
# Set the number of the distribution
small = 200
medium = 500
large = 1000
# Function to sample from a mixed Gaussian distribution
sample_mixed_gaussian = function(n, means, vars, probs) {
# Determine which mixture component each sample comes from
components = sample(length(probs), size = n, replace = TRUE, prob = probs)
rnorm(n, mean = means[components], sd = sqrt(vars[components]))
}
# Generate samples
samples_normal_small_1 = rnorm(small, mean1, sqrt(var1))
samples_normal_medium_1 = rnorm(medium, mean1, sqrt(var1))
# Generate samples
set.seed(123)
samples_normal_small_1 = rnorm(small, mean1, sqrt(var1))
samples_normal_medium_1 = rnorm(medium, mean1, sqrt(var1))
samples_normal_large_1 = rnorm(large, mean1, sqrt(var1))
samples_normal_small_2 = rnorm(small, mean2, sqrt(var2))
samples_normal_medium_2 = rnorm(medium, mean2, sqrt(var2))
samples_normal_large_2 = rnorm(large, mean2, sqrt(var2))
samples_small_mixed = sample_mixed_gaussian(small, c(mean_mix1, mean_mix2), c(var_mix1, var_mix2), prob_mix)
samples_medium_mixed = sample_mixed_gaussian(medium, c(mean_mix1, mean_mix2), c(var_mix1, var_mix2), prob_mix)
samples_large_mixed = sample_mixed_gaussian(large, c(mean_mix1, mean_mix2), c(var_mix1, var_mix2), prob_mix)
samples_t_small = rt(small, 4)
samples_t_medium = rt(medium, 4)
samples_t_large = rt(large, 4)
# Create a sequence of values to cover the relevant range (true density)
x_values_1 = seq(mean1 - 4*sqrt(var1), mean1 + 4*sqrt(var1), length.out = 300)
density_values_1 = dnorm(x_values_1, mean = mean1, sd = sqrt(var1))
x_values_2 = seq(mean2 - 4*sqrt(var2), mean2 + 4*sqrt(var2), length.out = 300)
density_values_2 = dnorm(x_values_2, mean = mean2, sd = sqrt(var2))
gmm_pdf = function(x) {
density1 = prob_mix[1] * (1 / (sqrt(2 * pi) * sqrt(var1))) * exp(-((x - mean1)^2) / (2 * sqrt(var1)^2))
density2 = prob_mix[2] * (1 / (sqrt(2 * pi) * sqrt(var2))) * exp(-((x - mean2)^2) / (2 * sqrt(var2)^2))
# Return the sum of the densities
return(density1 + density2)
}
x_values_mix = seq(-20, 40, length.out = 300)
density_values_mix = sapply(x_values_mix, gmm_pdf)
# Generate quantiles using DMQ model
# Set the parameters
vTau = seq(0.01, 0.99, length.out = 99)
# Generate fit for these three samples
Fit_small_1 = EstimateDMQ(vY = samples_normal_small_1, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_medium_1 = EstimateDMQ(vY = samples_normal_medium_1, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_large_1 = EstimateDMQ(vY = samples_normal_large_1, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_small_2 = EstimateDMQ(vY = samples_normal_small_2, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_medium_2 = EstimateDMQ(vY = samples_normal_medium_2, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_large_2 = EstimateDMQ(vY = samples_normal_large_2, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_small_3 = EstimateDMQ(vY = samples_small_mixed, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_medium_3 = EstimateDMQ(vY = samples_medium_mixed, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_large_3 = EstimateDMQ(vY = samples_large_mixed, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
Fit_small_4 = EstimateDMQ(vY = samples_t_small, vTau = vTau,
iTau_star = 50,  # Median as reference
FixReference = TRUE,
fn.optimizer = fn.solnp)
